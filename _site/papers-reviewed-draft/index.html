<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.15.1 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Review of Papers | Jérémie</title>
<meta name="description" content="Here is the draft of a list of the papers I have read with a short personal summary of them">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Jérémie">
<meta property="og:title" content="Review of Papers">
<meta property="og:url" content="https://jkobject.com/me/papers-reviewed-draft/">


  <meta property="og:description" content="Here is the draft of a list of the papers I have read with a short personal summary of them">



  <meta property="og:image" content="https://jkobject.com/me/assets/images/research.jpg">



  <meta name="twitter:site" content="@jkobject">
  <meta name="twitter:title" content="Review of Papers">
  <meta name="twitter:description" content="Here is the draft of a list of the papers I have read with a short personal summary of them">
  <meta name="twitter:url" content="https://jkobject.com/me/papers-reviewed-draft/">

  
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="https://jkobject.com/me/assets/images/research.jpg">
  

  







  
    <meta property="article:publisher" content="https://www.facebook.com/jkobject">
  

  


<link rel="canonical" href="https://jkobject.com/me/papers-reviewed-draft/">





  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Organization",
      "url": "https://jkobject.com/me",
      "logo": "https://jkobject.com/me/assets/images/id.png"
    }
  </script>



  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Jeremie Kalfon",
      "name": "Jeremie Kalfon",
      "url": "https://jkobject.com/me",
      "sameAs": ["https://twitter.com/jkobject","https://LinkedIn.com/in/jkobject","https://ResearchGate.com/jeremie-kalfon"]
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/me/feed.xml" type="application/atom+xml" rel="alternate" title="Jérémie Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/me/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<link rel="apple-touch-icon" sizes="180x180" href="/me/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/me/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/me/favicon-16x16.png">
<link rel="manifest" href="/me/site.webmanifest">
<link rel="mask-icon" href="/me/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#2b5797">
<meta name="theme-color" content="#ffffff">

<!-- end custom head snippets -->
  </head>

  <body class="layout--single wide">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-logo" href="/me/"><img src="/me/assets/images/id-88.png"></a>
        <a class="site-title" href="/me/">Jérémie K.</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/me/about/" title="I am a human. I wish to make the world better with science. <3">About</a>
            </li><li class="masthead__menu-item">
              <a href="/me/projects/" title="">Projects</a>
            </li><li class="masthead__menu-item">
              <a href="/me/opinions/" >Opinions</a>
            </li><li class="masthead__menu-item">
              <a href="/me/ideas/" >Ideas</a>
            </li><li class="masthead__menu-item">
              <a href="/me/blog/" title="A short extract about my life experiences.">Blog</a>
            </li><li class="masthead__menu-item">
              <a href="/me/papers/" >Papers</a>
            </li><li class="masthead__menu-item">
              <a href="/me/courses/" title="Here is the list of the Courses I have received and the one I have given.">Courses</a>
            </li><li class="masthead__menu-item">
              <a href="/me/culture/" title="This is my personal list of books, Comics and films I love.">Culture</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  











<div class="page__hero--overlay"
  style=" background-image: url('/me/assets/images/research.jpg');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          Review of Papers

        
      </h1>
      
        <p class="page__lead">Here is the draft of a list of the papers I have read with a short personal summary of them
</p>
      
      
      
      
    </div>
  
  
    <span class="page__hero-caption">thanks to dribble for this amazing design
</span>
  
</div>




  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="https://jkobject.com/me/" itemprop="item"><span itemprop="name">Home</span></a>
          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        <li class="current">Review of Papers</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/me/assets/images/id.png" alt="Jérémie Kalfon" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Jérémie Kalfon</h3>
    
    
      <p class="author__bio" itemprop="description">
        I am an Engineer, Researcher and Entrepreneur. I wish to make the world a better place with science!
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Paris - Boston</span>
        </li>
      

      
        
          
            <li><a href="https://twitter.com/jkobject" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
          
        
          
            <li><a href="https://Scholar.google.com/citations?user=zyXiydsAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Scholar</a></li>
          
        
          
            <li><a href="https://LinkedIn.com/in/jkobject" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
          
        
      

      

      
        <li>
          <a href="mailto:jkobject@gmail.com">
            <meta itemprop="email" content="jkobject@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Review of Papers">
    <meta itemprop="description" content="Here is the draft of a list of the papers I have read with a short personal summary of them">
    
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu">
  <li><a href="#summary">SUMMARY</a></li>
  <li><a href="#combining-models-of-protein-translation-and-population-genetics-to-predict-protein-production-rates-from-codon-usage-patterns">Combining Models of Protein Translation and Population Genetics to Predict Protein Production Rates from Codon Usage Patterns</a></li>
  <li><a href="#explaining-complex-codon-usage-patterns-with-selection-for-translational-efficiency-mutation-bias-and-genetic-drift">Explaining complex codon usage patterns with selection for translational efficiency, mutation bias, and genetic drift</a></li>
  <li><a href="#estimating-gene-expression-and-codon-specific-translational-efficiencies-mutation-biases-and-selection-coefficients-from-genomic-data-alone">Estimating Gene Expression and Codon-Specific Translational Efficiencies, Mutation Biases, and Selection Coefficients from Genomic Data Alone</a></li>
  <li><a href="#quantifying-codon-usage-in-signal-peptides-gene-expression-and-amino-acid-t-usage-explain-apparent-selection-for-inefficient-codons">Quantifying codon usage in signal peptides: Gene expression and amino acid T usage explain apparent selection for inefficient codons</a></li>
</ul>
            </nav>
          </aside>
        
        <hr />
<h4 id="summary">SUMMARY</h4>

<p>What is the research problem the paper attempts to address? Consider
	What is the motivation of the research work?
	What problem does it attempt to resolve?
	Is it addressing weaknesses in existing approaches?
	Does it challenge an existing research paradigm?</p>

<p>What are the claimed contributions of the paper? What is new/original in this paper?
	A new question or research area?
	A new understanding of a research problem?
	A new algorithm/experimental method/proof technique/methodology for solving problems?
	A new breed of software tools or systems?
	A new formalism or notation?
	New evidence to substantiate or disprove a previously published claim?</p>

<p>How do the authors substantiate their claims? What makes the claims scientific?
	What is the methodology adopted to substantiate the claims?
	What is the argument of the paper?
	What are the major theorems?
	What experiments are conducted?  Look at:
	data analyses/simulations/benchmarks/user studies/cases studies/examples</p>

<p>What are the conclusions? 
	What is to be learnt from the paper?
	Will standard practice in the field be changed as result of the findings?
	Are the results generizable?
	Can the results be applied to other areas of the field?
	What are the open problems?</p>

<h3 id="evaluation">EVALUATION</h3>

<p>Is the research problem significant?
	Does the work only address a minor problem?§
	Does it deepen understanding?
	Does it explore new design ideas?</p>

<p>Are the contributions significant?
	Is the paper worth reading?
	Are the authors simply repeating the state of the art?
	Are there real surprises?
	Are the authors aware of the relation of their work to the existing literature?
	Is the paper addressing a well-known open problem?</p>

<p>Are the claims valid (and modest enough)?
	have the authors (intentionally or unintentionally) cut corners?
	Has the right theorem been proven?</p>

<h3 id="synthesis">SYNTHESIS</h3>

<p>What is the crux of the research problem?
What are some alternative approaches to address the problem?
What is a better way to substantiate the claim of the authors?
What is a good argument against the case made by the authors?
How can the research results be improved?
Can the research results be applied to another context?
What are the open problems raised by this work?
Can we do better than the authors?</p>

<hr />

<h3 id="attention-in-a-bayesian-framework---sahani">Attention in a bayesian framework - sahani</h3>

<p>-&gt; atention as a byesian inference. to improve impoverish stimulus
appearance of a limitation == bottleneck in such framework</p>

<p>shouldn’t you know about P to compute this minimization ? page 7</p>

<p>pb :</p>

<h3 id="neural-coding--peter-latham">neural coding  Peter latham</h3>

<p>neurons send and receive outputs which noise can be correlated meaning that there is in fact information in it. This can have a huge effect when looking at big number of neurons. We have to knwo the correlation to understand the coding as the neurons do</p>

<p>the effect of correlation can be expressed as the variation of I_shuffled ( for encoding) &amp; of I_diag for decoding information adn saying if correlation are important in this process. those values can be from 0 to 40% of the total information of the neurons</p>

<p>ICA ?
independent component analysis. if we admit that a signal is composed of multiple independent sources, each of them emitting an information (thus the corresponding random variable expresses Dependant outcomes) It is possible to each sources ( or each independent components) from the signal according to $y = Wx + o$ with W a matrix (like a Neural net) x the input and o the noise. it is part of unsupervised learning of features</p>

<p>pb : the noise is not gaussian as estimated here.</p>

<h3 id="cracking-the-neural-code-peter-latham">cracking the neural code –peter latham</h3>

<p>The Equivalence of Information-Theoretic and Likelihood-Based Methods for Neural Dimensionality Reduction Manesh sahani</p>

<p>This paper is reviewing many modern information theoretic and stochastic methods to decipher the information encoded in spikes according to stimulus. It expresses concerns and solutions for the MID methods and present some new architectures as well.</p>

<p>pb :</p>

<p>self calibrating NN for dimensionality reduction Chklovskii</p>

<p>A NN that is calibrating itself to its input and reduce the dimensionality the best way possible according to minimization rules. present online and offline with rules and reguralizers which creates update rules that can be attributed to hebbian &amp; anti hebbian behavior in neurons.</p>

<p>pb : not really biologically plausible</p>

<h3 id="alex-graves-talk-at-ijcnn">Alex graves talk at IJCNN</h3>

<p>can use ActiveComputationTimeNN to know where are the important part of the data 
DifferentiableNeuralComputer? NTM</p>

<p>DecoupledNeuralInterface to stop using backprop ( as efficient)</p>

<h3 id="neural-turing-machine-graves">neural turing machine Graves</h3>

<p>where does the vector emission of the heads comes from ? 
the NN
for examples the shifts are produced by a softmax layer applied to the output of the controller 
softmax : mise a l’expo de chaques val du vect avec normalization sur le vector ( sum =1)</p>

<p>cross entropy : objective function that uses entropy function of two stat distribution and the log loss function</p>

<p>objective function :  fonction d’apprentissage that needs to be minimized ( it gets the output and the hoped output)</p>

<p>Evolving Neural Networks through Augmenting Topologies - Kenneth O stanley</p>

<p>really nice paper, explained well, but few complexity though.</p>

<p>What if this evolving architecture leads you to train your growing NN over simplification of your data and it gets more and more complex (for images for example) and you could have different types of neurons with different acti function …</p>

<h3 id="predicting-the-sequence-specificities-of-dna--and-rna-binding-proteins-by-deep-learning-brendan-frey">Predicting the sequence specificities of DnA- and RnA-binding proteins by deep learning Brendan Frey</h3>

<p>k-mer ?
all the possible substrings of length k that are contained in a string</p>

<p>mini-batch  ?   stochastic gradient descent ?
In gradient descent algorithms, you can calculate the sum of gradients with respect to several examples and then update the parameters using this cumulative gradient. 
If you ‘see’ all training examples before one ‘update’, then it’s called full batch learning. 
If you use only one example, it’s called stochastic gradient descent (online learning). 
If you use a small batch of examples, it’s called mini-batch learning.</p>

<p>nesterov momentum ?
a way o compute how we move in our gradient descent, that is, using a momentum and in addition we give this an acceleration in the way we computer it which is called accelerated momentum (it seems to converge quicker)</p>

<p>hyperparameter search ?
a way to find the best set of parameters for a ML algo either by doing them all or by inferring a function from them if such exist.</p>

<p>alternative splicing ?
when a gene encodes many proteins trough specific selection during the RNA “epissage” == “splicing”</p>

<p>metazoa ?
eucaryotes with different tissue types</p>

<p>sequence specificity protein ?
proteins that binds inside the holes in coiled DNA or RNA in specific places regulating their transcription in many ways</p>

<h3 id="deep-learning-free-text-and-sentence-embedding--sanjeev-arora">Deep-learning-free Text and Sentence Embedding  –Sanjeev Arora</h3>
<p><a href="http://www.offconvex.org/2018/06/17/textembeddings/">link</a></p>

<p>like word2vec but for phrases</p>

<ul>
  <li>you weight each word by its inverse smoothed frequency</li>
  <li>you sum the weighted vectors</li>
  <li>you remove the component that is present in any possible phrases (corresponds to points etc..)</li>
</ul>

<p>to produce phrases you have a discourse vector representing the subject
and you have a proba function of a vector appearing at pos t given discourse vector. ct moves as a random walk</p>

<h3 id="how-do-we-capture-structure-in-relational-data-sanjeev">How do we capture structure in relational data –Sanjeev</h3>

<p>we want to have a representation of the vertices (points) that is similar
when vertices pertain to a similar neighborhood do this by learning a representation that allows us to guess what will be the next given the preceding in a random walk</p>

<p>with node2vec there is 2 ways to look at neighborhoods (homophily or structural) and you can interpolate between the two with 2 hyper params</p>

<h3 id="cancer-metastasis-detection-with-neural-conditional-random-field-yi-li">Cancer Metastasis Detection With Neural Conditional Random Field –Yi Li</h3>

<p>we want to use an information of the neighborhood of images the we find by computing an additional term on the inference of each elements according to their similarity/ distance to others and their labels. this creates a differentiable loss function (Conditional Random Field) that allows for fast computations etc. 80% success</p>

<h3 id="systematic-identification-of-phosphorylation--mediated-protein-interaction-switches">Systematic identification of phosphorylation- mediated protein interaction switches</h3>

<p>phosphorilation plays a regulatory role in prot-prot interaction by modifying the efficiency of functional domains.</p>

<p>from binding, enzymatic functions …</p>

<p>(only using simple probabilistic methods given the presence of such amino acids and other chemical parameters..) -not well explained thought</p>

<p>there is much to do here but needs even more data and need clear characterization of the multiple effects of the folding in the chemical processes of phospho switches</p>

<h3 id="a-polymorphism-in-the-tumor-suppressor-p53-affects-aging-and-longevity-in-mouse-models">A polymorphism in the tumor suppressor p53 affects aging and longevity in mouse models</h3>

<p>p53 if polymorph increase cancer probability but also increases life expectancy by preventing the knowing off of genes useful in cell replication and decreases stem cell exhaustion.</p>

<h3 id="gene2vector">gene2vector</h3>

<p>really just applying the word2vect algorithm on protein sequences and inferring some interesting results like the destructuring or presence of proteins</p>

<h3 id="multi-omics-factor-analysis---a-framework-for-unsupervised-integration-of-multi-omic-data-sets--ricard-argelaguet-et-al">Multi-Omics factor analysis - a framework for unsupervised integration of multi-omic data sets – Ricard Argelaguet et al.</h3>

<p>you integrate each data by doing a PCA on them basically.
but it uses a Latent factor model which is formulated in a bayesian way by Bayesian way. it i able to recover sparse features which explain well the underlying variations in the data and are able to thus predict outcomes in clinical data and importance features in pluripotent cell differentiation
NICE.</p>

<p>It is super efficient computationally (compared to similar methods)</p>

<h3 id="basset-learning-the-regulatory-code-of-the-accessible-genome-with-deep-convolutional-neural-networks--david-kelley">Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks – David Kelley</h3>

<p>you can learn the functional activity of ncDNA with a CNN and DNA seq (==FAIRE seq) data (ground truth here)</p>

<blockquote>
  <p>understanding the DNA–protein interactions as a function of the un- derlying sequence.</p>
</blockquote>

<p>Given training data, models parameterized by machine learning can effectively predict protein binding, DNA accessibility, histone modifications, and DNA methylation from the sequence</p>

<p>provide much information on relationship to diseases and allow fast training by reusing the weights to train on other datasets the first CNN weights are predictive of known binding configurations as well as unknown ones. (should be investigated)</p>

<h3 id="machine-theory-of-mind">Machine theory of Mind</h3>

<p>How to interpret and predict another agent’s thinking according to its behavior.</p>
<blockquote>
  <p>This “learning to learn” about new agents is what we mean by meta-learning</p>
</blockquote>

<p>principal characteristics is that the network can learn that the agent hold false belief about their environment</p>

<h3 id="analysis-of-genomic-sequence-motifs-for-deciphering-transcription-factor-binding-and-transcriptional-regulation-in-eukaryotic-cells-valentina-boeva">Analysis of Genomic Sequence Motifs for Deciphering Transcription Factor Binding and Transcriptional Regulation in Eukaryotic Cells –Valentina Boeva</h3>

<blockquote>
  <p>A eukaryotic genome contains a variety of structured patterns. A far from exhaustive list of genomic patterns includes (i) tandem repeats and transposable elements, (ii) stretches of GC- or AT-rich sequences (e.g., CpG islands in mammalian genomes), (iii) binding sites of DNA associated proteins (e.g., transcription factor binding sites), (iv) splice sites, and (v) DNA and RNA binding sites of non- coding RNA molecules. Different patterns may overlap each other. Therefore, although this review is focused on motifs for transcription factor binding sites (TFBSs), we provide a short overview of other types of genomic patterns.</p>
</blockquote>

<p>This is an overview of the different Trans Fact Bind Sites TFBS and the Motifs Repeats, AT-GC rich sequences, splice sites, miRNA binding sites, techniques and DB to use, find, retrieve known or unknownTFBS.</p>

<p><em>contains DB links to unknown DB of PWM motifs for TFBS</em></p>

<p>discovery of Shadow binding sites that are low affinity binding sites that alone are not capable of retaining the TF long enough to ensure activation/repression, but instead are used to maintain a high concentration of TF in the vicinity of the primary binding sites</p>

<h3 id="gpu-kernels-for-block-sparse-weights-scott-gray-openai">GPU Kernels for Block-Sparse Weights –Scott Gray, openAI</h3>

<p>increasing drastically computation speed on NN with blocks of zero valued weights, allowing to deepen or widen dense NN for same computational efficiency and better accuracy.</p>

<p>They use LSTMs with internal networks and connects them according to the small world paradigm (very good results)</p>

<p>–&gt; would be nice to learn the sparsity structure
according to a predefined sparsity structure, a small world and block sparse  property</p>

<p>Available on tensorflow ops.
(best use multiples of 32x32 and small float values 16 bits etc..
best minibatch is 64 (for cache dilution)</p>

<h3 id="node2vec-scalable-feature-learning-for-networks--aditya-grover-stanford">node2vec: Scalable Feature Learning for Networks – Aditya Grover, stanford</h3>

<p>How to embed a node from a network using a flexible notion of neighborhood (from random walks)</p>

<p>able to classify predict … from this representation, which involves just creating an encoding matrix that is learnt by asyncSGD by trying to predict the neighborhood given the representation</p>

<p><em>questions</em></p>

<p>What if we set out to encode not solely the local neighborhood but also some information of the distant neighborhood considering the prior that the network has the small world property?</p>

<h3 id="microrna-signature-analysis-in-colorectal-cancer-identification-of-expression-profiles-in-stage-ii-tumors-associated-with-aggressive-disease-kah-hoong-chang">MicroRNA signature analysis in colorectal cancer: identification of expression profiles in stage II tumors associated with aggressive disease –Kah Hoong Chang</h3>

<p><em>touse</em></p>

<p>Very High quality paper with a demonstration that 3 circulating miRNA
Can provide information on the colorectal cancer and its reaction to different treatment strategies, for personalized curration of the cancer, this association amongst more than 400 different miRNA (using micro array + microfluidics PCR)  was performed using an ANN to learn how to classify patients</p>

<h3 id="efficient-and-robust-automated-machine-learning-matthias-feurer-freiburg-university">Efficient and Robust Automated Machine Learning –Matthias Feurer, Freiburg University</h3>

<p>they build on the work of auto weka to solve the CASH optimization (hyperparams and model) problem, to create state of the art algo with sota performance using a tree based Bayesian method (random forest based) called SMAC. They improve this model by having a first instantiation step using meta learning: they have a model that have learnt what are the best instantiation for a given dataset using meta feature of the dataset such as entropy, number of points, classes etc… .
and secondly they use an ensembl of their best algo and not just one</p>

<h3 id="vicus-exploiting-local-structures-to-improve-network-based-analysis-of-biological-data--bo-wang-serafim-batzoglou">Vicus: Exploiting local structures to improve network-based analysis of biological data – Bo Wang, Serafim Batzoglou</h3>

<p><em>touse</em></p>

<p>They propose a new method to the manifold learning problem (dim reduction, clustering, classification etc..) Which uses local dimension learning to do its magic instead of the usual laplacian eigenvectors which learn comparing global euclidean distances.</p>

<p>It is basically the same thing as the laplacian but only it is constrained to do its computation on a local subgraph of close by datapoints</p>

<p><em>contains DB links to unknown DB of single cell RNA (12-15, 24)</em></p>

<h3 id="active-learning-of-cortical-connectivity-from-two-photon-imaging-data-mart-́ın-a-bertra-́n-duke-uni">Active learning of cortical connectivity from two-photon imaging data –Mart ́ın A. Bertra ́n, Duke Uni</h3>

<p>using bi photon imaging to look at a set of neuron activities and inferring some networks of connections given some stimulus using active learning. 
Basically, what edge should be added to the network that would maximize the likelihood of the model. (edges are weighted)
They model it with a GLM trying to optimize the BIC value of the model. to find whether promising edges to be added can be, it tries to drive the spiking rate of the model up.</p>

<h3 id="finding-syntax-in-human-encephalography-with-beam-search-john-hale-oxf-deepmind">Finding Syntax in Human Encephalography with Beam Search –John Hale, Oxf, DeepMind</h3>

<blockquote>
  <p>a pattern of results recommends the RNNG+beam search combination as a mechanistic model of the syntactic processing that occurs during normal human language comprehension</p>
</blockquote>

<p>RNNG are generative models (here for text) that rely on RNN. they can create a sentence or form a grammar tree of words given a sentence, a tree that you can parse within using beam search this parsing gives you information such as word surprisal and you can use these different statistics given the tree to generate different phrases that will create a predictable effect on the human brain meaning the way their syntax is generated is predictable of the human language comprehension.</p>

<p>The guys basically made a point in cognitive neuroscience using ANN and advanced computer science. <strong>MADNESS</strong></p>

<h3 id="glow-flow-based-generative-network-openai">GLOW: FLow based generative network –OpenAI</h3>

<p>It is a particular kind of generative NN that is fully reversible thus encode^-1 == decode it is like an auto-encoder but without the re parametrization trick and with a latent space that is the same size as the input space. in the latent space you just have a multi dim Gaussian you can then interpolate to generate new inputs. 
(costly to train though)</p>

<h3 id="prediction-of-acute-myeloid-leukemia-risk-in-healthy-individuals-eran-segal-moritz-gerstung">Prediction of acute myeloid leukemia risk in healthy individuals –Eran Segal, Moritz Gerstung</h3>

<p>age-related clonal haematopoiesis is a phenomenon is a phenomenon that exists during aging but also is an indicator of AML 7yr before getting it (leukemia form). Here they try to differentiate between the two using deep sequencing methods they find a group of SNPs and markers in parts of the sequences that explains together much of the data but not enough separately. they then did the same on regular blood samples of patients and have seen that information on the size of hematopoetic cells (blood) have a correlation with age related diseases but also pre AML conditions. thus enabling a first easy screening of risky patients.</p>

<h3 id="a-synthetic-diploid-benchmark-for-accurate-variant-calling-evaluation--mc-arthur">A synthetic-diploid benchmark for accurate variant-calling evaluation – Mc Arthur</h3>

<p>trying to create a new benchmark for variant calling tools (matching reads to a reference genome and inferring the SNPs) this is faster than de novo WGS which is super costly and long. (this is part of NGS) they use a particular type of cell lines (human) called CHM which are diploids but fully homozygous and allows to use PACbio sequences without mixing the two genomes</p>

<h3 id="meta-analysis-of-the-diagnostic-and-clinical-utility-of-genome-and-exome-sequencing-and-chromosomal-microarray-in-children-with-suspected-genetic-diseases--michelle-clark">Meta-analysis of the diagnostic and clinical utility of genome and exome sequencing and chromosomal microarray in children with suspected genetic diseases – Michelle Clark</h3>

<p>A literature and statistical review of 10 years of genomics medicine for infant genetic diseases diagnostics. better use WES/WGS than previous method called CMA (molecular analysis) better sequence infant and 2 parents as well than jsut infant. a lot of heterogeneity and thus. take stats in this study with a grain of salt.</p>

<h3 id="multi-scale-deep-tensor-factorization-learns-a-latent-representation-of-the-human-epigenome--jacob-schreiber-uw">Multi-scale deep tensor factorization learns a latent representation of the human epigenome – Jacob Schreiber UW</h3>

<p><em>touse</em></p>

<p>let’s create an embedding of all epigenomics data. “Avocado” 
<em>quality article</em></p>
<blockquote>
  <p>o high-throughput assay is perfectly reproducible, and run-to-run differences in the same experiment may reflect either biological variation in the cells being assayed or experimental variance arising from sample preparation or downstream steps in the protocol. Finally, many epigenomic assays are highly redundant with one another, and many cell types are closely related to each other, leading to highly redundant measurements</p>
</blockquote>

<p>–&gt; so Embeddings
factorize an incomplete 3D matrix of epigenetic features into 3 2D matx of different feature types (pos, assays, cells), concatenating features for each pos on the matrix and passing through 2 * 2048 dense layers NN.</p>

<p>maybe try to train on predicting different features to have more generalization
train on ENCODE instead of RoadMap.. etc.
is it fully differentiable ?
How is the vector factorization working?
how is it constrained?
…</p>
<h3 id="machine-learning-applications-in-genetics-and-genomics--william-noble-uw">Machine learning applications in genetics and genomics – William Noble, UW</h3>

<p>a review of every possible machine learning applications in genomics</p>

<h3 id="bioambients-an-abstraction-for-biological-compartments">BioAmbients: An abstraction for biological compartments</h3>

<p>Ambient Calculus, a further abstraction of PI calculus, can be the mathematical base to design a framework for abstracting biological compartments</p>

<p>Basically how to design a framework for a code allowing us to simulate cells and their inner/outer processes. Bio ambient seems to be the most general mathematical framework. Available in BioSpi</p>

<p>further improvement such as duplicate, divide, erase, destroy, 3D… needs to be achieved</p>

<h3 id="personal-clinical-history-predicts-antibiotic-resistance-in-urinary-tract-infections--yelinsnitsernovich">Personal clinical history predicts antibiotic resistance in urinary tract infections -Yelin,Snitser,Novich</h3>

<p>Using Israel’s DB and stat explore they have shown that there is relation to many parameter from urinary tracks infection and other factors and related them to biological known factors. using those predictive factors, one would be able to predict the risk of such infection and to prevent it. Among the interesting factors, relation with location (old age institute etc) pharmaceutical history, cross relations eg between age/sex.</p>

<h3 id="deciphering-regulatory-dna-sequences-and-noncoding-genetic-variants-using-neural-network-models-of-massively-parallel-reporter-assays---rajiv-movva-kundaje">Deciphering regulatory DNA sequences and noncoding genetic variants using neural network models of massively parallel reporter assays - Rajiv Movva, Kundaje</h3>

<p><em>touse</em></p>

<p>We can see how using a NN model trained to predict regulatory effects of SNP on non coding sequences from Multi array analysis datasets works well. It was used together with SNPs found in GWAS for some genetically correlated cardiac diseases. some interesting results but MPRA dataset is of poor quality in general (low correlation)
Big step forward thought.</p>

<h3 id="clinical-concept-embeddings-learned-from-massive-sources-of-medical-data--andrew-l-beam1-benjamin-kompa-unc-harvard">Clinical Concept Embeddings Learned from Massive Sources of Medical Data – Andrew L Beam1, Benjamin Kompa UNC, Harvard</h3>

<p>They manage to show 100,000 clinical concepts embeddings from 3 different data-sources, they compare them to other state of the art methods on different sets of benchmark they created using clinical data sources. They achieve the biggest dataset of embedding with sota results on most of the softs·</p>

<h3 id="pooled-screens-in-human-cells-david-feldman-el-al">pooled screens in human cells, David Feldman el al</h3>

<p>there is the introduction of doing targeted fluorescent in situ sequencing ( sequencing of specific genes from within the cell by using the fluorescence sequencing method of sequencing by synthesis.) in addition, inferring the specificities of the cell (morphology, dynamics and interaction) and to link genetic variations to</p>

<h3 id="manifold-tiling-localized-receptive-fields-are-optimal-in-similarity-preserving-neural-networks-pehlevan-tepper-fi-ccb">Manifold-tiling Localized Receptive Fields are Optimal in Similarity-preserving Neural Networks, Pehlevan, Tepper FI CCB</h3>

<p>we can see a bio plausible NN optimization function relying on Hebb. anti Hebb. neurons which can uncover the manifold in a set of data (Here done with symmetric datasets) even for highly dim. datasets. Also showing a link to kernel learning (Here it is obviously an unsupervised learning technique,)</p>

<h3 id="can-deep-learning-improve-genomic-prediction-of-complex-human-traits---pau-bellot-et-al">Can deep learning improve genomic prediction of complex human traits? - Pau Bellot et al</h3>

<p>tried to regress human traits values (waist, hips, height, bone
106 heel mineral density (BHMD), body mass index (BMI), systolic blood pressure (SBP)) using MLP, CNN &amp; LR over SNPs from WGAS. 
<em>very stupid idea if you ask me. it is not how CNN are supposed to work. It is really treating DL as magic here</em></p>

<h3 id="learning-graph-level-representation-for-drug-discovery--junying-li-et-al">Learning Graph-Level Representation for Drug Discovery – Junying Li et. al.</h3>

<p>They use GCN to extract embeddings from a network representing atoms linked together (i.e. a molecule). They use a dummy super node to represent the entire molecule in one feature and they are able to classify the molecule between ones that works and ones that don’t</p>

<h3 id="multiplier-a-transfer-learning-framework-reveals-systemic-features-of-rare-autoimmune-disease--jaclyn-n-taroni-et-al">MultiPLIER: a transfer learning framework reveals systemic features of rare autoimmune disease – Jaclyn N. Taroni et. al.</h3>

<p><em>touse</em></p>

<p>multiplier is a method of using Plier (an NMF method to extract features related to gene interactions) on a large compendium of data from many gene interaction modification in multiple diseased over multiple tissues from MicroArray data. learning on a huge multivariate dataset allows the unsupervised embeddings to be richer and more precise in what they convey. They demonstrated that they were able to find feature (and thus genetic interactions for many different complex diseases. the model tries also to make similar vectors from similar tissues and diseases, aligned.
<em>quality paper</em></p>

<h3 id="on-entropy-and-information-in-gene-interaction-networks--z-s-wallace1-s-b-rosenthal">On entropy and information in gene interaction networks – Z. S. Wallace1, S. B. Rosenthal</h3>

<p>An information concept to extract from interaction networks, some subsets that are correlated or related together. It is complementary to other enrichment methods and can find relationships amongst diseases, metabolic pathways and genes with relation to phenotypic characteristics.
and recover many interesting relationships that have been found by researchers along the way.</p>

<p><em>DisGeNet</em>
<em>InBioMap</em>
<em>UNIPROT</em>
<em>MSigDB</em>
<em>GeneOntology</em></p>

<p><em>plus présenter les derniers problèmes et questionement durant les résultats (ou on en est maintenant)</em></p>

<p><em>raconter aussi les résultat légèrement en mode histoire de ce qu’on a fait.</em></p>

<h3 id="allele-specific-binding-of-rna-binding-proteins-reveals-functional-genetic-variants-in-the-rna--ei-wen-yang-jae-hoon-bahn">Allele-specific binding of RNA-binding proteins reveals functional genetic variants in the RNA – Ei-Wen Yang, Jae Hoon Bahn</h3>

<p><em>eCLIP-Seq</em></p>

<p>GV of diseases DB:
<em>GWAS, COSMIC, ClinVar, CIVIC and iGAP</em></p>

<p><em>touse</em></p>

<p>A method to find Allele specific binding events using eCLIP-seq data (trancriptome-wide protein RNA interaction data) which gives enough data to do it in an allele specific manner, the method filters out biases in the data and appears to give SOTA results. It predicted functional SNV and how they act as regulators from direct observation instead of correlation inference
“we expect that allele-specific analyses of eCLIP will be an essential approach to deciphering the function of non-coding variants in the RNA.”</p>

<h3 id="in-silico-prediction-of-high-resolution-hi-c-interaction-matrices-shilu-zhang1-deborah-chasman">In silico prediction of high-resolution Hi-C interaction matrices –Shilu Zhang1, Deborah Chasman.</h3>

<p><em>touse</em></p>

<p>to predict the contact count of two genomic regions from their one-dimensional regulatory signals which output from HiC-Reg can be used to identify significant interactions using peak-calling algorithms that have as good experimental support as those from true counts.
a regression-based framework to predict interactions between pairs
of regions across multiple cell lines by integrating published Hi-C datasets with one-dimensional regulatory genomic datasets.</p>

<h3 id="winner-take-all-autoencoders--brendan-frey">Winner-Take-All Autoencoders – Brendan Frey</h3>

<p>winner-take-all spatial and lifetime sparsity methods to train auto-encoders that learn to do fully-connected and convolutional sparse coding which jointly trains the encoder and decoder paths by direct back-propagation, and does not require an iterative EM-like optimization technique during training. sota results especially when doing semi supervised training</p>

<h3 id="dissecting-splicing-decisions-and-cell-to-cell-variability-with-designed-sequence-libraries--eran-segal-martin-mikl">Dissecting splicing decisions and cell-to-cell variability with designed sequence libraries – Eran Segal, Martin Mikl</h3>

<p>rationally designed libraries, consisting of altogether 32,789 variants, to address fundamental questions in splicing regulation considering the process in its entirety, from the processing of the RNA to the level of the final functional gene product. They could reproducibly detect even small changes in splicing ratios and quantitatively predict splicing of novel variants with high accuracy (R2 between 0.76 and 0.85)
cells evolved to have seemingly “suboptimal” splice sites, which maximizes the potential for dynamic regulation, but can also serve to ensure optimality at the level of protein isoforms. They have established an assay that is able to assess the cell-to-cell variability of splicing decisions in large scale by measuring the protein output of alternative isoforms and shown that the level of stochasticity can be encoded in the DNA.</p>

<p><strong>Highly rich paper</strong></p>

<h3 id="quantum-entanglement-in-neural-network-states--dong-ling-deng-xiaopeng-li">Quantum Entanglement in Neural Network States – Dong-Ling Deng, Xiaopeng Li</h3>

<p>the entanglement proper- ties of neural-network quantum states in the RBM architecture. and proof that all short-range RBM states satisfy an area law of entanglement for arbitrary dimensions and bipartition geometry
For some maximal volume- law entanglement RBM representation is remarkably efficient, requiring only a small number of parameters scaling linearly with the system size which show the power of NN to describe massive entanglement
Further explore the link between ANN and entangled quantum states…</p>

<h3 id="cancer-archetypes-co-opt-and-adapt-the-transcriptional-programs-of-existing-cellular-states--maayan-baron1-isabella-s-kim">Cancer archetypes co-opt and adapt the transcriptional programs of existing cellular states – Maayan Baron1, Isabella S. Kim</h3>

<p><strong>quality paper</strong></p>

<p>study of the gene expression of individual cancer cells in zebrafish and human melanomas. three recurring gene expression patterns across melanoma cancer cells which we refer to as ‘archetypes’ because they appear to be co-opted cellular states with distinct spatial location
cancer cells between human and zebrafish melanomas exhibit the same transcriptional program.
not yet purview into the origin of archetypes. found cooperation across cancer cell lines as they form a tumor in vivo</p>

<h3 id="deep-learning-sequence-based-ab-initio-prediction-of-variant-effects-on-expression-and-disease-risk--troyanskaya-fi">Deep learning sequence-based ab initio prediction of variant effects on expression and disease risk – Troyanskaya, FI</h3>
<p><strong>addition of the second paper “Predicting effects of noncoding variants with deep learning–based sequence model”,</strong> especially the method part of it.</p>

<p><em>touse</em></p>

<p>they have used a deep CNN with a lot of different Weighted patterns to predict regulatory profile (chromatin, methylation etc…) from a raw DNA sequence. using ENCODE datasets given specific cell types. this gave them the ability to predict a cell specific profile as well as to predict variation in regulatory profiles caused by variants, using a linear model (made from non linear basis function of from the different profiles data, they are able to regress how much each the regulatory features of the non coding sequence before the  Transcription Start Site (and a bit of the sequence after) influence the expression profile of different the gene.) they were able to retrieve expression for famous protein and how they change with different cells and to retrieve SNPs causing variation in expression that were also shown from GWAS information (even better than in GWAS) and to find interesting disease correlations as well.</p>

<h3 id="one-shot-imitation-learning--ilya-sutskever-pieter-abbeel">One-Shot Imitation Learning – Ilya Sutskever, Pieter Abbeel</h3>

<p>a paper displaying the use of DQN with two distinct networks, one with an attentional mechanism (LSTLM) that sets a set of subtasks to achieve the objective, one to control the robot given the subtasks(MLP) (or even just reconstruct the sets of tasks given the final state it needs to achieve) Here the attentional system helps to subdivide the sets of tasks given to the MLP, results are SOTA for the type of tasks (first to achieve that)</p>

<h3 id="mcm2-promotes-symmetric-inheritance-of-modified-histones-during-dna-replication--nataliya-petryk-maria-dalby">MCM2 promotes symmetric inheritance of modified histones during DNA replication – Nataliya Petryk, Maria Dalby</h3>

<p><em>not very interesting</em></p>

<p>special sequencing technique revealed that parental histone segregation is almost symmetrical with a weak inherent preference for the leading strand. making it possible for MCM2 to recycle parental histones to the lagging strand (Fig. 3F, right), while a separate pathway deposits pa- rental histones on the leading strand. In this vein, it is conceivable that histone segregation can be regulated during development to drive asymmetric cell fates.</p>

<h3 id="deep-surveying-of-alternative-splicing-complexity-in-the-human-transcriptome-by-high-throughput-sequencing--qun-pan-ofer-shai-frey">Deep surveying of alternative splicing complexity in the human transcriptome by high-throughput sequencing – Qun Pan, Ofer Shai, Frey</h3>

<p><em>old article</em> 2008</p>

<p>explaining how the splicing complexity can be understood using RNA seq and how there may be a lot of possible transcripts from one sequence with different alternative splicing according to some regulatory sequences. one interesting aspect is that it shows how much there is and the amount we did not really knew about previously.</p>

<h3 id="sequential-regulatory-activity-prediction-across-chromosomes-with-convolutional-neural-networks-david-r-kelley-yakir-a-reshef">Sequential regulatory activity prediction across chromosomes with convolutional neural networks. –David R. Kelley, Yakir A. Reshef</h3>

<p><em>touse</em></p>

<p>bassenji is another DL algorithm to quantify regulatory features (certain - DNase seq, histone, Chip-seq) from CAGE experiments. it is using a CNN with expending layers (which multiply the ROI by a factor of 2 at each layers). it is from 16 month ago and appears to be less good than more recent work but provide trainings for coverage, GC%, EM for multi-reading alignment etc..
It shows link to eQTL found similarities and GWAS data, perform prediction of why some diseases happens etc, while preventing bias from LD. finally it is giving new research ideas (more data, finding more distant reg activities, better cell specific data, more precise data) and post transcriptional regulation activities etc…</p>

<h3 id="deciphering-the-splicing-code--yoseph-barash-frey">Deciphering the splicing code — Yoseph Barash, Frey</h3>

<p><em>touse</em></p>

<p>Kinda the previous version to deepBind. Here they describe an information theoretic method based on regression for prediction of variation of splicing probabilities compared to the baseline activity. this is used by taking in account typical base patterns that would create specific sec shape or bindings for the splicing to happen in a specific manner. This allowed the discovery of new features that make alternative splicing possible and of variation in different tissue with phenotypic logics behind.</p>

<h3 id="impala--deepmind">IMPALA – DeepMind</h3>

<p>A new DeepQN framework for the in parallel training of multiple actors and diminishing the delay/dissimilarity between the actors and the learners (and the learners to themselves) this framework/architecture is made possible by a new learning method that tries to combat the off policy (dissimilarity in policy) between the different agents. it uses previous work on batch A2C, Importance sampling, and other mathematically/experimentally driven techniques to compute the best possible gradient for episodes (a,s,r).</p>

<h3 id="unsupervised-embedding-of-single-cell-hi-c-data---jie-liu-galip-gurkan-yardımcı-uw">Unsupervised embedding of single-cell Hi-C data - Jie Liu, Galip Gurkan Yardımcı, UW</h3>

<p>a paper displaying how one can use a previous technique called HiCRep which smooths the Hi-C contact matrix and then computes a weighted similarity measure separately at each genomic distance. Then averages the results for the cell itself. Finally followed by a Multidimensional Scaling (MDS) of the resulting matrix to reduce the dimensionality while preserving distance relations, allows to recover angle distance between datapoints (representing cells) which allows the classification of different cell phases. It can be done with high throughput scHiC data since using a subset of contacts still allows to recover the ground truth, especially if used in combination with a bag  of more deeply sequenced cells.</p>

<h3 id="an-integrated-encyclopedia-of-dna-elements-in-the-human-genome--encode">An integrated encyclopedia of DNA elements in the human genome – ENCODE</h3>

<p><strong>start of the Engineer’s map</strong></p>

<p>a detailed explanation of the types of data and means to get them from the encode collaboration. And an overview of this data. Interesting feedbacks from it. It displays the different things that might be achieved using it. 
Moreover it provides access and a biologically oriented summary of numerous research that have been undertaken by the consortium’s researchers. Especially their results and how they fit in a more general summary of this kind of functional genomics data.</p>

<h3 id="engineering-stem-cell-organoids--xiaolei-yin-benjamin-e-mead">Engineering Stem Cell Organoids – Xiaolei Yin Benjamin E. Mead</h3>

<p>an overview of the different use, techniques, and methods for the construction of organoids or organoids like objects from human stem cells. recapitulating OoC HoC etc. And talking about how a mix of these methods is required for the future of organoids engineering.</p>

<h3 id="advantages-and-limitations-of-current-network-inference-methods--riet-de-smet-and-kathleen-marchal">Advantages and limitations of current network inference methods – Riet De Smet and Kathleen Marchal</h3>

<p>a survey of the different network inference methods in genomics, to predict the regulatory network (in bacterial genomes) with the different algorithms that are available and their mathematical framework. The different DB that are available and the problematics and usages that everyone can have from these according to one’s needs.</p>

<h3 id="optimization-techniques-on-riemannian-manifolds--steven-smith">Optimization Techniques on Riemannian Manifolds – Steven Smith</h3>

<p>two algorithms: Newton’s method and the conjugate gradient method on Riemannian manifolds, are presented and shown to possess resp. quadratic and super-linear convergence</p>

<h3 id="the-tsetlin-machine---a-game-theoretic-bandit-driven-approach-to-optimal-pattern-recognition-with-propositional-logic--granmo">The Tsetlin Machine - A Game Theoretic Bandit Driven Approach to Optimal Pattern Recognition with Propositional Logic – Granmo</h3>

<p>the tsetlin machine is a form of machine learning techniques which uses tsetlin automaton the same way a neural network uses a neuron. However it is more computationally grounded by being in the framework of propositional logic. The paper shows how to reach an equilibrium in learning even from very noisy data by finding the right hyperparameter handling error assignment. it proves that it will be able to learn anything and then shows some sota results on some datasets. Moreover the paper derives CNN and RNN like structures from tsetlin machines.</p>

<h3 id="the-genetics-of-transcription-factor-dna-binding-variation--deplancke">The Genetics of Transcription Factor DNA Binding Variation – Deplancke</h3>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Since most of variant associated with phenotypic changes in mammals are from non coding region, the paper establishes the different mode of genetic variation mediated changes to TF binding. sets up the ways in which they have previously been uncovered, some examples and the difficulties behind this problem. It then goes on to highlight the possible technological (sequencing &amp; computational(ML))-based techniques that might help in solving it.
</code></pre></div></div>

<h3 id="seganndb-interactive-web-based-genomic-segmentation-hocking">SegAnnDB interactive Web-based genomic segmentation –Hocking</h3>

<p>a less interesting paper that reuses a mathematical framework to help on analysis (segmentation) of cancer genomes into different categories (CN variation, breakpoints(DNA deleted, inverted, or swapped)) by using a mathematical+vision framework to understand the user input segmentation and further them to the entirety of the cell genome in a supervised fashion.</p>

<h3 id="defining-a-cancer-dependency-map--aviad-tsherniak-francisca-vazquez-phil-g-montgomery-broadinstitute">Defining a Cancer Dependency Map – Aviad Tsherniak, Francisca Vazquez, Phil G. Montgomery BroadInstitute</h3>

<p>Researchers from CDS team at the broad present their ongoing effort to analyze a wide range of cancer cell lines to infer their dependencies (survival, reproduction) on different genes. To do so they are using genome scale loss of function RNAi screens (knocking down specific genes using silencing RNA which will get infiltrated by lentiviral infection in vitro on microArray live cell chips which is highly multiplexed (looking at the expression of the co-infected GFP RNA in each cases)). Each input RNA (shRNA ~100,000) will infect some cells and silence some genes. They contain a seed which will help in the binding to the desired mRNA.<br />
However, Because of this seed, this will also create off target effects (down-regulating other genes than the desired one by partial binding of the miRNA seed) it is using a linear regression model to understand the true effect of each shRNA in silencing a particular gene. (The model was in fact very similar in intuition to a NMF but was just a linear regression: to divide the dataset (cell line perturbation per shRNA) into two distinct part: cell line perturbation per gene knock down and cell line perturbation (instead of gene knock down) per shRNA with seed k) &lt;– could be done in a more efficient fashion by using an NMF which divide it and add a third matrix term which would contain the off target effect relation across shRNAs. 
The two matrix found allow one to understand specific cases where specific cell lines require a particular gene more than another and more than the regular cell. it is called: a differential dependency and might represent important therapeutic target. 
By taking the strongest ones (6std from the mean) they found 769 such genes for the 500 cell lines. they then used another non linear regression model with gene mutations, gene copy number, gene expression from the Cancer Cell Line Encyclopedia (CCLE).
They then carefully analyzed the different types of predictive MDPs (Marker dependency pairs) and specific MDPs for 86% of the dependencies.
However, to find a full range of MDP and predictive models for each, they estimate they would need to increase the amount of cell lines to &gt;5000, to account for other types of dependencies such as ones that are not single cell specific (but are important in group behavior).
–&gt; moreover, what happen for gene combination effects and in this case, time dependent gene known down effect? is there a non linear relationship between gene knockdown and gene knockoff? what about the many different type of cancer cells and their inter relationship present in a tumor?
how many other features can be added? (long range TF?) can one reuse some pretrained DL for genomic and find what molecular features in the sequence explain each types?</p>

<h3 id="improved-estimation-of-cancer-dependencies-from-large-scale-rnai-screens-using-model-based-normalization-and-data-integration--james-mcfarland-broadinstitute">Improved estimation of cancer dependencies from large-scale RNAi screens using model-based normalization and data integration – james McFarland BroadInstitute</h3>

<p><em>basically about explanaing demeter2</em></p>

<p>explaining similar things as previously with a bit more emphasis in the comparative aspect and computational aspect of Demeter2 to other types of data. a larger dataset (790dtp). in the better explanation of the model and its results. interesting and deeper explanation of the computation in the methods:
the demeter2 model uses a Bayesian model with variational inference of some params and MAP estimates of others. it explains the full procedure to infer each params using scipy and Edward. in this model a lot has been used to find the best set of parameters / hyperparameters. comparing with ground truth or prior knowledge and values to set to test the strength of each.</p>

<h3 id="genetic-and-transcriptional-evolution-alters-cancer-cell-line-drug-response--uri-ben-david1-benjamin-siranosian-gavin-ha-helen-tang-yaara-oren-kunihiko-hinohara-craig-strathdee-joshua-dempster-nicholas-lyons-robert-burns-anwesha-nag-guillaume-kugener-beth-cimini-peter-tsvetkov-yosef-maruvka1-ryan-orourke-anthony-garrity-andrew-tubelli-pratiti-bandopadhay-aviad-tsherniak">Genetic and transcriptional evolution alters cancer cell line drug response – Uri Ben-David1, Benjamin Siranosian, Gavin Ha, Helen tang, Yaara Oren, Kunihiko Hinohara, craig Strathdee, Joshua Dempster, Nicholas lyons, robert Burns, Anwesha Nag, Guillaume Kugener, Beth cimini, Peter tsvetkov, Yosef Maruvka1, ryan O’rourke, Anthony Garrity, Andrew tubelli, Pratiti Bandopadhay, Aviad tsherniak</h3>

<p>Here we look at the problems arising from the culture of cancer cell lines in research application. because of random mutations, changes in their environment, cancer cell lines undergo evolution. this creates strong differences to the in vivo scenario. The paper tries to infer the possible differences and how they might arise (medium, population bottleneck). They have dev a tool to compute the distance to a reference. They also show how to use this such as to understand cancer cooperation (with single cell seq) and correlation genotype-phenotype.</p>

<h3 id="massively-multilingual-sentence-embeddings-for-zero-shot-cross-lingual-transfer-and-beyond--mikel-artetxe-holger-schwenk">Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond – Mikel Artetxe, Holger Schwenk.</h3>

<p>the papers show the power of many different languages used to create a same embeddings for all. it displays encoding techniques and train / test strategies and a new test set. It proves to be sota on most test set used. I uses a bi-LSTM encoder of 5 layers, 83 languages and an LSTM decoder  with skip connections</p>

<h3 id="cytogan-generative-modeling-of-cell-images--imaging-platform-broad-institute-of-mit-and-harvard">CytoGAN: Generative Modeling of Cell Images – Imaging Platform Broad Institute of MIT and Harvard</h3>

<p>this work uses a regular LSGAN to learn the important feature from a dataset of cell images. they show that it is not sota but can infer better latent factors which encode phenotypic information about the cell. both in the generator and discriminator. They show how to preprocess the image to get the best results. the work would need additional information to be reproducible.</p>

<h3 id="pathway-perturbations-in-signaling-networks-linking-genotype-to-phenotype-babu-for-barth-epfl">Pathway perturbations in signaling networks: Linking genotype to phenotype –Babu for Barth EPFL</h3>

<blockquote>
  <blockquote>
    <p>what about gene knockdown datasets… might be very interesting. 
drug interference data sets as well.
I heard of central regulators which are specific and specifically expressed in specific cancer cell lines and that knowing that information allows one to understand the specificities of the cell line (like its reaction to drugs etc..)</p>
  </blockquote>
</blockquote>

<p>In here we look at several different signaling pathways which have highly oncogenic potentials. looking at them via a What mutation, how it should work, what happens when mutations. How can it be fixed.
We are really looking at the causal explanation of a phenotype by a mutation/alt. splicing/ translocation/… .</p>

<h3 id="pharmacogenomics-of-gpcr-drug-targets---masuho-leonie-j-jahn-kirill-a-martemyanov-david-e-gloriam-m-madan-babu">Pharmacogenomics of GPCR Drug Targets –  Masuho, Leonie J. Jahn, Kirill A. Martemyanov, David E. Gloriam, M. Madan Babu</h3>

<p>Here we analyze how different drugs affecting primarily or secondarily the GPCR membrane receptors of cells can have different effects considering the naturally occurring mis-sense variation in the human population on these corresponding protein coding genes.</p>

<blockquote>
  <p>how comme they never thought of doing the same in pharmacollogy??
what about the non coding variants in the population it will reflect also some differential effects in the signaling pathway and even variation in the proportion of membrane receptors</p>
</blockquote>

<p>###</p>

<blockquote>
  <p>I really want to see how the pipeline to integrate the entire G cycle looks like.</p>
</blockquote>

<h3 id="papers-gilchrist">Papers Gilchrist</h3>
<h4 id="combining-models-of-protein-translation-and-population-genetics-to-predict-protein-production-rates-from-codon-usage-patterns">Combining Models of Protein Translation and Population Genetics to Predict Protein Production Rates from Codon Usage Patterns</h4>

<h4 id="explaining-complex-codon-usage-patterns-with-selection-for-translational-efficiency-mutation-bias-and-genetic-drift">Explaining complex codon usage patterns with selection for translational efficiency, mutation bias, and genetic drift</h4>

<h4 id="estimating-gene-expression-and-codon-specific-translational-efficiencies-mutation-biases-and-selection-coefficients-from-genomic-data-alone">Estimating Gene Expression and Codon-Specific Translational Efficiencies, Mutation Biases, and Selection Coefficients from Genomic Data Alone</h4>

<h4 id="quantifying-codon-usage-in-signal-peptides-gene-expression-and-amino-acid-t-usage-explain-apparent-selection-for-inefficient-codons">Quantifying codon usage in signal peptides: Gene expression and amino acid T usage explain apparent selection for inefficient codons</h4>

<p>I had the time to read the papers you sent me and they were very good. The third one presented a great introduction to CUB and a good model which attains a very high score. I would guess that this model could not get the same score for other species. I still think that a model of CUB would always be reductionist as the CUB is a proxy for so many different processes and adaptations of the cell. The many fine grained Bayesian model that you present however seems to make sense and creating a model is to me the only way to test a theory. The ability to regress values such as the protein synthesis rate is impressive and it does not seem trivial to me that this should be the case. The model that you have developed seems very suited for answering questions about the CUB as shown for example in “quantifying codon usage in signal peptides”.</p>

<h3 id="where-genome-biology-is-going-next">Where genome biology is going next</h3>
<p>multiple researchers giving their view of where genomics is heading</p>

<h3 id="a-topological-and-conformational-stability-alphabet-for-multipass-membrane-proteins--patrick-barth">A topological and conformational stability alphabet for multipass membrane proteins – Patrick Barth</h3>

<p>Here is the study of multipass transmembrane proteins which are composed of many transmembrane helices. they have a specific confirmation which is dictated by their sequence. interaction between helices yields the specific shape of thee multipass prot.
specific residues which help connect the helices and give them their shape seems to be coevolving, stabilizing the shape and are determinant of the topology. For the first time this study analyzed trimers of helices insetead of dimers.</p>

<h3 id="primer-on-deep-learning-in-genomics">Primer on Deep Learning in Genomics</h3>

<h3 id="a-guide-to-dl-in-healthcare--andre-esteva-alexandre-robicquet">A guide to DL in healthcare – Andre Esteva, Alexandre robicquet</h3>

<p>Some simple yet necessary ideas about how one would best use DL in healthcare and what are the future and promises of it.</p>

<h3 id="mammalian-genes-are-transcribed-with-widely-different-bursting-kinetics">Mammalian Genes Are Transcribed with Widely Different Bursting Kinetics</h3>

<h3 id="unsupervised-embedding-of-single-cell-hi-c-data--jie-liu-galip-gu-rkan-yardımcı-uw">Unsupervised embedding of single-cell Hi-C data – Jie Liu, Galip Gu rkan Yardımcı UW</h3>

<h3 id="detecting-circular-rna-from-high-throughput-sequence-data-with-de-bruijn-graph--xin-li-and-yufeng-wu">Detecting Circular RNA from High-throughput Sequence Data with de Bruijn Graph – Xin Li and Yufeng Wu</h3>

<h3 id="advancing-the-aging-biology-toolkit--troy-k-coody-and-adam-l-hughes">Advancing the aging biology toolkit – TROY K COODY AND ADAM L HUGHES</h3>

<hr />


        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      
    </div>

    
  </article>

  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>

      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="mailto:jkobject@gmail.com" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email</a></li>
        
      
        
          <li><a href="https://twitter.com/jkobject" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/jkobject" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://ResearchGate.net/profile/jeremie_kalfon" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-researchgate" aria-hidden="true"></i> ResearchGate</a></li>
        
      
        
          <li><a href="https://Scholar.google.com/citations?user=zyXiydsAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Scholar</a></li>
        
      
        
          <li><a href="https://LinkedIn.com/in/jkobject" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
    

    <li><a href="/me/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2019 Jérémie Kalfon. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/me/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.6.0/js/all.js" integrity="sha384-z9ZOvGHHo21RqN5De4rfJMoAxYpaVoiYhuJXPyVmSs8yn20IE3PmBM534CffwSJI" crossorigin="anonymous"></script>




<script src="/me/assets/js/lunr/lunr.min.js"></script>
<script src="/me/assets/js/lunr/lunr-store.js"></script>
<script src="/me/assets/js/lunr/lunr-en.js"></script>





              <script>
                window.onload = function () {
                    var script = document.createElement('script');
                    var firstScript = document.getElementsByTagName('script')[0];
                    script.type = 'text/javascript';
                    script.async = true;
                    script.src = '/me/sw-register.js?v=' + Date.now();
                    firstScript.parentNode.insertBefore(script, firstScript);
                };
            </script>
            </body>

</html>
